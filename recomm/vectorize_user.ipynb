{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 11,
>>>>>>> 0fc819dd65671edfe4cb9b520a061bbe54361b3a
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "logging.basicConfig(\n",
    "\tformat='%(asctime)s : %(levelname)s : %(message)s',\n",
    "\tlevel=logging.INFO)\n",
    "\n",
<<<<<<< HEAD
    "cores = mp.cpu_count\n",
=======
    "cores = 8\n",
>>>>>>> 0fc819dd65671edfe4cb9b520a061bbe54361b3a
    "list_corpus = ['corpus/attraction_user.list',\n",
    "               'corpus/hotel_user.list',\n",
    "               'corpus/restaurant_user.list']\n",
    "list_user_model = ['model/attraction_user.model',\n",
    "                   'model/hotel_user.model',\n",
    "                   'model/restaurant_user.model']\n",
    "params_user = [{'size':300, 'window':99999, 'min_count':0,        # Attraction\n",
    "               'workers':cores, 'iter':100, 'sg':1, 'sample':1},\n",
    "               {'size':300, 'window':99999, 'min_count':0,        # Hotel\n",
    "               'workers':cores, 'iter':100, 'sg':1, 'sample':1},\n",
    "               {'size':300, 'window':99999, 'min_count':0,        # Restaurant\n",
    "               'workers':cores, 'iter':100, 'sg':1, 'sample':1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-19 15:26:44,796 : INFO : collecting all words and their counts\n",
      "2018-08-19 15:26:44,797 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-08-19 15:26:44,797 : INFO : pruned out 0 tokens with count <=1 (before 103, after 103)\n",
      "2018-08-19 15:26:44,798 : INFO : pruned out 61 tokens with count <=2 (before 103, after 42)\n",
      "2018-08-19 15:26:44,798 : INFO : pruned out 65 tokens with count <=3 (before 104, after 39)\n",
      "2018-08-19 15:26:44,798 : INFO : pruned out 64 tokens with count <=4 (before 101, after 37)\n",
      "2018-08-19 15:26:44,799 : INFO : pruned out 65 tokens with count <=5 (before 101, after 36)\n",
      "2018-08-19 15:26:44,799 : INFO : pruned out 65 tokens with count <=6 (before 101, after 36)\n",
      "2018-08-19 15:26:44,800 : INFO : pruned out 67 tokens with count <=7 (before 102, after 35)\n",
      "2018-08-19 15:26:44,800 : INFO : pruned out 68 tokens with count <=8 (before 104, after 36)\n",
      "2018-08-19 15:26:44,800 : INFO : pruned out 70 tokens with count <=9 (before 105, after 35)\n",
      "2018-08-19 15:26:44,801 : INFO : pruned out 72 tokens with count <=10 (before 107, after 35)\n",
      "2018-08-19 15:26:44,801 : INFO : pruned out 66 tokens with count <=11 (before 101, after 35)\n",
      "2018-08-19 15:26:44,802 : INFO : pruned out 66 tokens with count <=12 (before 101, after 35)\n",
      "2018-08-19 15:26:44,802 : INFO : pruned out 66 tokens with count <=13 (before 101, after 35)\n",
      "2018-08-19 15:26:44,803 : INFO : pruned out 66 tokens with count <=14 (before 101, after 35)\n",
      "2018-08-19 15:26:44,803 : INFO : pruned out 66 tokens with count <=15 (before 101, after 35)\n",
      "2018-08-19 15:26:44,803 : INFO : pruned out 67 tokens with count <=16 (before 102, after 35)\n",
      "2018-08-19 15:26:44,804 : INFO : pruned out 71 tokens with count <=17 (before 106, after 35)\n",
      "2018-08-19 15:26:44,804 : INFO : pruned out 66 tokens with count <=18 (before 101, after 35)\n",
      "2018-08-19 15:26:44,805 : INFO : pruned out 67 tokens with count <=19 (before 102, after 35)\n",
      "2018-08-19 15:26:44,805 : INFO : pruned out 66 tokens with count <=20 (before 101, after 35)\n",
      "2018-08-19 15:26:44,805 : INFO : pruned out 66 tokens with count <=21 (before 101, after 35)\n",
      "2018-08-19 15:26:44,806 : INFO : pruned out 66 tokens with count <=22 (before 101, after 35)\n",
      "2018-08-19 15:26:44,806 : INFO : pruned out 69 tokens with count <=23 (before 104, after 35)\n",
      "2018-08-19 15:26:44,807 : INFO : pruned out 66 tokens with count <=24 (before 101, after 35)\n",
      "2018-08-19 15:26:44,807 : INFO : pruned out 67 tokens with count <=25 (before 102, after 35)\n",
      "2018-08-19 15:26:44,808 : INFO : pruned out 66 tokens with count <=26 (before 101, after 35)\n",
      "2018-08-19 15:26:44,808 : INFO : pruned out 66 tokens with count <=27 (before 101, after 35)\n",
      "2018-08-19 15:26:44,809 : INFO : pruned out 68 tokens with count <=28 (before 103, after 35)\n",
      "2018-08-19 15:26:44,809 : INFO : pruned out 66 tokens with count <=29 (before 101, after 35)\n",
      "2018-08-19 15:26:44,809 : INFO : pruned out 110 tokens with count <=30 (before 145, after 35)\n",
      "2018-08-19 15:26:44,810 : INFO : pruned out 69 tokens with count <=31 (before 104, after 35)\n",
      "2018-08-19 15:26:44,810 : INFO : pruned out 66 tokens with count <=32 (before 101, after 35)\n",
      "2018-08-19 15:26:44,810 : INFO : pruned out 68 tokens with count <=33 (before 103, after 35)\n",
      "2018-08-19 15:26:44,811 : INFO : pruned out 66 tokens with count <=34 (before 101, after 35)\n",
      "2018-08-19 15:26:44,811 : INFO : pruned out 75 tokens with count <=35 (before 110, after 35)\n",
      "2018-08-19 15:26:44,812 : INFO : pruned out 66 tokens with count <=36 (before 101, after 35)\n",
      "2018-08-19 15:26:44,812 : INFO : pruned out 66 tokens with count <=37 (before 101, after 35)\n",
      "2018-08-19 15:26:44,813 : INFO : pruned out 75 tokens with count <=38 (before 110, after 35)\n",
      "2018-08-19 15:26:44,813 : INFO : pruned out 66 tokens with count <=39 (before 101, after 35)\n",
      "2018-08-19 15:26:44,813 : INFO : pruned out 73 tokens with count <=40 (before 108, after 35)\n",
      "2018-08-19 15:26:44,814 : INFO : pruned out 66 tokens with count <=41 (before 101, after 35)\n",
      "2018-08-19 15:26:44,814 : INFO : pruned out 66 tokens with count <=42 (before 101, after 35)\n",
      "2018-08-19 15:26:44,815 : INFO : pruned out 74 tokens with count <=43 (before 109, after 35)\n",
      "2018-08-19 15:26:44,815 : INFO : pruned out 66 tokens with count <=44 (before 101, after 35)\n",
      "2018-08-19 15:26:44,816 : INFO : pruned out 66 tokens with count <=45 (before 101, after 35)\n",
      "2018-08-19 15:26:44,816 : INFO : pruned out 66 tokens with count <=46 (before 101, after 35)\n",
      "2018-08-19 15:26:44,817 : INFO : pruned out 66 tokens with count <=47 (before 101, after 35)\n",
      "2018-08-19 15:26:44,817 : INFO : pruned out 67 tokens with count <=48 (before 102, after 35)\n",
      "2018-08-19 15:26:44,818 : INFO : collected 66 word types from a corpus of 13281 raw words and 5497 sentences\n",
      "2018-08-19 15:26:44,818 : INFO : Loading a fresh vocabulary\n",
      "2018-08-19 15:26:44,819 : INFO : effective_min_count=4 retains 35 unique words (53% of original 66, drops 31)\n",
      "2018-08-19 15:26:44,819 : INFO : effective_min_count=4 leaves 8552 word corpus (99% of original 8586, drops 34)\n",
      "2018-08-19 15:26:44,819 : INFO : deleting the raw counts dictionary of 66 items\n",
      "2018-08-19 15:26:44,820 : INFO : sample=1 downsamples 35 most-common words\n",
      "2018-08-19 15:26:44,821 : INFO : downsampling leaves estimated 801 word corpus (9.4% of prior 8552)\n",
      "2018-08-19 15:26:44,821 : INFO : estimated required memory for 35 words and 300 dimensions: 101500 bytes\n",
      "2018-08-19 15:26:44,821 : INFO : resetting layer weights\n",
      "2018-08-19 15:26:44,823 : INFO : training model with 3 workers on 35 vocabulary and 300 features, using sg=0 hs=0 sample=1 negative=5 window=0\n",
      "2018-08-19 15:26:44,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\", line 164, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 773, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 703, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "  File \"mtrand.pyx\", line 993, in mtrand.RandomState.randint\n",
      "ValueError: low >= high\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\", line 164, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 773, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 703, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "  File \"mtrand.pyx\", line 993, in mtrand.RandomState.randint\n",
      "ValueError: low >= high\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spent = []\n",
    "for i in range(3):\n",
    "    with open(list_corpus[i], 'rb') as f:\n",
    "        corpus = pickle.load(f)\n",
    "    start = time.time()\n",
    "    model = Word2Vec(corpus, **params_user[i])\n",
    "    spent.append('Elapsed time: '+str(time.time() - start)+' sec'+' ['+list_user_model[i]+']')\n",
    "    model.wv.save(list_user_model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in spent:\n",
    "    print(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
