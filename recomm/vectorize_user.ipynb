{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "\tformat='%(asctime)s : %(levelname)s : %(message)s',\n",
    "\tlevel=logging.INFO)\n",
    "\n",
    "cores = 4\n",
    "\n",
    "list_places = ['data/kor/attraction_places.csv',\n",
    "               'data/kor/hotel_places.csv',\n",
    "               'data/kor/restaurant_places.csv']\n",
    "list_corpus = ['corpus/user-score-based_attraction.list',\n",
    "               'corpus/user-score-based_hotel.list',\n",
    "               'corpus/user-score-based_restaurant.list']\n",
    "list_user_model = ['model/attraction_user.model',\n",
    "                   'model/hotel_user.model',\n",
    "                   'model/restaurant_user.model']\n",
    "#              size window min  workers iter sg sample\n",
    "params_user = [{'size':300, 'window':99999, 'min_count':0,\n",
    "               'workers':cores, 'iter':100, 'sg':1, 'sample':1},\n",
    "               {'size':300, 'window':99999, 'min_count':0,\n",
    "               'workers':cores, 'iter':100, 'sg':1, 'sample':1},\n",
    "               {'size':300, 'window':99999, 'min_count':0,\n",
    "               'workers':cores, 'iter':100, 'sg':1, 'sample':1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-19 15:26:44,796 : INFO : collecting all words and their counts\n",
      "2018-08-19 15:26:44,797 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-08-19 15:26:44,797 : INFO : pruned out 0 tokens with count <=1 (before 103, after 103)\n",
      "2018-08-19 15:26:44,798 : INFO : pruned out 61 tokens with count <=2 (before 103, after 42)\n",
      "2018-08-19 15:26:44,798 : INFO : pruned out 65 tokens with count <=3 (before 104, after 39)\n",
      "2018-08-19 15:26:44,798 : INFO : pruned out 64 tokens with count <=4 (before 101, after 37)\n",
      "2018-08-19 15:26:44,799 : INFO : pruned out 65 tokens with count <=5 (before 101, after 36)\n",
      "2018-08-19 15:26:44,799 : INFO : pruned out 65 tokens with count <=6 (before 101, after 36)\n",
      "2018-08-19 15:26:44,800 : INFO : pruned out 67 tokens with count <=7 (before 102, after 35)\n",
      "2018-08-19 15:26:44,800 : INFO : pruned out 68 tokens with count <=8 (before 104, after 36)\n",
      "2018-08-19 15:26:44,800 : INFO : pruned out 70 tokens with count <=9 (before 105, after 35)\n",
      "2018-08-19 15:26:44,801 : INFO : pruned out 72 tokens with count <=10 (before 107, after 35)\n",
      "2018-08-19 15:26:44,801 : INFO : pruned out 66 tokens with count <=11 (before 101, after 35)\n",
      "2018-08-19 15:26:44,802 : INFO : pruned out 66 tokens with count <=12 (before 101, after 35)\n",
      "2018-08-19 15:26:44,802 : INFO : pruned out 66 tokens with count <=13 (before 101, after 35)\n",
      "2018-08-19 15:26:44,803 : INFO : pruned out 66 tokens with count <=14 (before 101, after 35)\n",
      "2018-08-19 15:26:44,803 : INFO : pruned out 66 tokens with count <=15 (before 101, after 35)\n",
      "2018-08-19 15:26:44,803 : INFO : pruned out 67 tokens with count <=16 (before 102, after 35)\n",
      "2018-08-19 15:26:44,804 : INFO : pruned out 71 tokens with count <=17 (before 106, after 35)\n",
      "2018-08-19 15:26:44,804 : INFO : pruned out 66 tokens with count <=18 (before 101, after 35)\n",
      "2018-08-19 15:26:44,805 : INFO : pruned out 67 tokens with count <=19 (before 102, after 35)\n",
      "2018-08-19 15:26:44,805 : INFO : pruned out 66 tokens with count <=20 (before 101, after 35)\n",
      "2018-08-19 15:26:44,805 : INFO : pruned out 66 tokens with count <=21 (before 101, after 35)\n",
      "2018-08-19 15:26:44,806 : INFO : pruned out 66 tokens with count <=22 (before 101, after 35)\n",
      "2018-08-19 15:26:44,806 : INFO : pruned out 69 tokens with count <=23 (before 104, after 35)\n",
      "2018-08-19 15:26:44,807 : INFO : pruned out 66 tokens with count <=24 (before 101, after 35)\n",
      "2018-08-19 15:26:44,807 : INFO : pruned out 67 tokens with count <=25 (before 102, after 35)\n",
      "2018-08-19 15:26:44,808 : INFO : pruned out 66 tokens with count <=26 (before 101, after 35)\n",
      "2018-08-19 15:26:44,808 : INFO : pruned out 66 tokens with count <=27 (before 101, after 35)\n",
      "2018-08-19 15:26:44,809 : INFO : pruned out 68 tokens with count <=28 (before 103, after 35)\n",
      "2018-08-19 15:26:44,809 : INFO : pruned out 66 tokens with count <=29 (before 101, after 35)\n",
      "2018-08-19 15:26:44,809 : INFO : pruned out 110 tokens with count <=30 (before 145, after 35)\n",
      "2018-08-19 15:26:44,810 : INFO : pruned out 69 tokens with count <=31 (before 104, after 35)\n",
      "2018-08-19 15:26:44,810 : INFO : pruned out 66 tokens with count <=32 (before 101, after 35)\n",
      "2018-08-19 15:26:44,810 : INFO : pruned out 68 tokens with count <=33 (before 103, after 35)\n",
      "2018-08-19 15:26:44,811 : INFO : pruned out 66 tokens with count <=34 (before 101, after 35)\n",
      "2018-08-19 15:26:44,811 : INFO : pruned out 75 tokens with count <=35 (before 110, after 35)\n",
      "2018-08-19 15:26:44,812 : INFO : pruned out 66 tokens with count <=36 (before 101, after 35)\n",
      "2018-08-19 15:26:44,812 : INFO : pruned out 66 tokens with count <=37 (before 101, after 35)\n",
      "2018-08-19 15:26:44,813 : INFO : pruned out 75 tokens with count <=38 (before 110, after 35)\n",
      "2018-08-19 15:26:44,813 : INFO : pruned out 66 tokens with count <=39 (before 101, after 35)\n",
      "2018-08-19 15:26:44,813 : INFO : pruned out 73 tokens with count <=40 (before 108, after 35)\n",
      "2018-08-19 15:26:44,814 : INFO : pruned out 66 tokens with count <=41 (before 101, after 35)\n",
      "2018-08-19 15:26:44,814 : INFO : pruned out 66 tokens with count <=42 (before 101, after 35)\n",
      "2018-08-19 15:26:44,815 : INFO : pruned out 74 tokens with count <=43 (before 109, after 35)\n",
      "2018-08-19 15:26:44,815 : INFO : pruned out 66 tokens with count <=44 (before 101, after 35)\n",
      "2018-08-19 15:26:44,816 : INFO : pruned out 66 tokens with count <=45 (before 101, after 35)\n",
      "2018-08-19 15:26:44,816 : INFO : pruned out 66 tokens with count <=46 (before 101, after 35)\n",
      "2018-08-19 15:26:44,817 : INFO : pruned out 66 tokens with count <=47 (before 101, after 35)\n",
      "2018-08-19 15:26:44,817 : INFO : pruned out 67 tokens with count <=48 (before 102, after 35)\n",
      "2018-08-19 15:26:44,818 : INFO : collected 66 word types from a corpus of 13281 raw words and 5497 sentences\n",
      "2018-08-19 15:26:44,818 : INFO : Loading a fresh vocabulary\n",
      "2018-08-19 15:26:44,819 : INFO : effective_min_count=4 retains 35 unique words (53% of original 66, drops 31)\n",
      "2018-08-19 15:26:44,819 : INFO : effective_min_count=4 leaves 8552 word corpus (99% of original 8586, drops 34)\n",
      "2018-08-19 15:26:44,819 : INFO : deleting the raw counts dictionary of 66 items\n",
      "2018-08-19 15:26:44,820 : INFO : sample=1 downsamples 35 most-common words\n",
      "2018-08-19 15:26:44,821 : INFO : downsampling leaves estimated 801 word corpus (9.4% of prior 8552)\n",
      "2018-08-19 15:26:44,821 : INFO : estimated required memory for 35 words and 300 dimensions: 101500 bytes\n",
      "2018-08-19 15:26:44,821 : INFO : resetting layer weights\n",
      "2018-08-19 15:26:44,823 : INFO : training model with 3 workers on 35 vocabulary and 300 features, using sg=0 hs=0 sample=1 negative=5 window=0\n",
      "2018-08-19 15:26:44,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\", line 164, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 773, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 703, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "  File \"mtrand.pyx\", line 993, in mtrand.RandomState.randint\n",
      "ValueError: low >= high\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\", line 164, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)\n",
      "  File \"C:\\Users\\CypressRH\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 773, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 703, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "  File \"mtrand.pyx\", line 993, in mtrand.RandomState.randint\n",
      "ValueError: low >= high\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Attraction\n",
    "df_place = pd.read_csv(list_places[0], names=['placeId', 'name', 'location', 'class'], encoding='ms949')\n",
    "with open(list_corpus[0], 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "start = time.time()\n",
    "model = Word2Vec(corpus, **params_user[0])\n",
    "print(\"Elapsed time: %s sec\" % (time.time() - start),' [',place,']')\n",
    "model.wv.save(list_user_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotel\n",
    "df_place = pd.read_csv(list_places[1], names=['placeId', 'name', 'location', 'class'], encoding='ms949')\n",
    "with open(list_corpus[1], 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "start = time.time()\n",
    "model = Word2Vec(corpus, *(params_user[1]))\n",
    "print(\"Elapsed time: %s sec\" % (time.time() - start),' [',place,']')\n",
    "model.wv.save(list_user_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restaurant\n",
    "df_place = pd.read_csv(list_places[2], names=['placeId', 'name', 'location', 'class'], encoding='ms949')\n",
    "with open(list_corpus[2], 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "start = time.time()\n",
    "model = Word2Vec(corpus, *(params_user[2]))\n",
    "print(\"Elapsed time: %s sec\" % (time.time() - start),' [',place,']')\n",
    "model.wv.save(list_user_model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399    광화문\n",
      "Name: name, dtype: object\n",
      "223    경복궁\n",
      "Name: name, dtype: object\n",
      "281    국립현대미술관 서울관\n",
      "Name: name, dtype: object\n",
      "102    망원시장\n",
      "Name: name, dtype: object\n",
      "98    익선동한옥거리\n",
      "Name: name, dtype: object\n",
      "239    이화 벽화마을\n",
      "Name: name, dtype: object\n",
      "243    국립국악박물관\n",
      "Name: name, dtype: object\n",
      "160    국립국악원\n",
      "Name: name, dtype: object\n",
      "145    창경궁\n",
      "Name: name, dtype: object\n",
      "382    서울숲\n",
      "Name: name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jahn/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "top10 = model_attr.wv.most_similar(positive=['320359','324887'], negative=['1958940'])\n",
    "for place in top10:\n",
    "    print(df_places[df_places['placeId'] == int(place[0])].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
